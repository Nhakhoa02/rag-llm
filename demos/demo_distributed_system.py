#!/usr/bin/env python3
"""
Distributed Vector Storage System Demo

This script demonstrates the distributed architecture in action.
It shows how the system handles:
- Multiple storage nodes
- Fault tolerance
- Load balancing
- Data replication
- Consistency management
"""

import asyncio
import os
import sys
import tempfile
import shutil
import time
import requests
import json
from pathlib import Path
from typing import List, Dict, Any

# Add the project root to the Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from data.storage.distributed_storage_manager import create_distributed_storage_manager
from data.storage.distributed_vector_store import VectorNode
from core.models.document import Document

def print_header(title):
    """Print a formatted header."""
    print("\n" + "=" * 60)
    print(f"üöÄ {title}")
    print("=" * 60)

def print_section(title):
    """Print a formatted section."""
    print(f"\nüìã {title}")
    print("-" * 40)

def check_node_health(node_id, host, port):
    """Check if a node is healthy."""
    try:
        response = requests.get(f"http://{host}:{port}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            return {
                "node_id": node_id,
                "status": "healthy",
                "load": data.get("load", 0.0),
                "vector_count": data.get("vector_count", 0),
                "uptime": data.get("uptime", 0)
            }
        else:
            return {"node_id": node_id, "status": "unhealthy", "error": f"HTTP {response.status_code}"}
    except Exception as e:
        return {"node_id": node_id, "status": "unreachable", "error": str(e)}

async def demo_distributed_system():
    """Main demonstration function."""
    print_header("Distributed Vector Storage System Demo")
    
    print("üéØ This demo showcases:")
    print("   ‚úÖ Multiple storage nodes")
    print("   ‚úÖ Fault tolerance")
    print("   ‚úÖ Load balancing")
    print("   ‚úÖ Data replication")
    print("   ‚úÖ Consistency management")
    print("   ‚úÖ Scalability")
    
    # Step 1: Check Node Health
    print_section("Step 1: Checking Node Health")
    
    nodes = [
        ("node1", "localhost", 8001),
        ("node2", "localhost", 8002),
        ("node3", "localhost", 8003)
    ]
    
    healthy_nodes = 0
    for node_id, host, port in nodes:
        health = check_node_health(node_id, host, port)
        status_emoji = "‚úÖ" if health["status"] == "healthy" else "‚ùå"
        print(f"{status_emoji} {node_id} ({host}:{port}): {health['status']}")
        
        if health["status"] == "healthy":
            healthy_nodes += 1
            print(f"   Load: {health.get('load', 0):.2f}")
            print(f"   Vectors: {health.get('vector_count', 0)}")
            print(f"   Uptime: {health.get('uptime', 0):.1f}s")
        else:
            print(f"   Error: {health.get('error', 'Unknown')}")
    
    if healthy_nodes < 2:
        print("\n‚ö†Ô∏è  Warning: Need at least 2 healthy nodes for fault tolerance!")
        print("   Please start the nodes with: python start_vector_nodes.py")
        return
    
    print(f"\n‚úÖ {healthy_nodes}/3 nodes are healthy - system ready!")
    
    # Step 2: Initialize Distributed Storage Manager
    print_section("Step 2: Initializing Distributed Storage Manager")
    
    vector_nodes = [VectorNode(node_id, host, port) for node_id, host, port in nodes]
    
    storage_manager = create_distributed_storage_manager(
        nodes=vector_nodes,
        replication_factor=2,
        consistency_level="quorum",
        shard_count=8,
        vector_size=384
    )
    
    print("‚úÖ Distributed storage manager initialized")
    print(f"   Replication factor: 2")
    print(f"   Consistency level: quorum")
    print(f"   Shard count: 8")
    print(f"   Vector size: 384")
    
    # Step 3: Create Test Collection
    print_section("Step 3: Creating Test Collection")
    
    collection_name = "demo_collection"
    success = await storage_manager.create_index(collection_name, 384)
    
    if success:
        print(f"‚úÖ Created collection: {collection_name}")
    else:
        print(f"‚ùå Failed to create collection: {collection_name}")
        return
    
    # Step 4: Upload Test Documents
    print_section("Step 4: Uploading Test Documents")
    
    test_documents = [
        Document(
            id="doc1",
            content="Distributed systems are computer systems that consist of multiple nodes working together to achieve a common goal.",
            type="document",
            metadata={"topic": "distributed_systems", "difficulty": "intermediate"}
        ),
        Document(
            id="doc2",
            content="Vector databases store and index high-dimensional vectors for similarity search and machine learning applications.",
            type="document",
            metadata={"topic": "vector_databases", "difficulty": "advanced"}
        ),
        Document(
            id="doc3",
            content="Fault tolerance is the ability of a system to continue operating even when some components fail.",
            type="document",
            metadata={"topic": "fault_tolerance", "difficulty": "basic"}
        ),
        Document(
            id="doc4",
            content="Load balancing distributes incoming requests across multiple servers to optimize resource utilization.",
            type="document",
            metadata={"topic": "load_balancing", "difficulty": "intermediate"}
        ),
        Document(
            id="doc5",
            content="Consistency models define how data consistency is maintained across distributed nodes in a system.",
            type="document",
            metadata={"topic": "consistency", "difficulty": "advanced"}
        )
    ]
    
    success = await storage_manager.upsert_documents(collection_name, test_documents)
    
    if success:
        print(f"‚úÖ Uploaded {len(test_documents)} documents")
        for doc in test_documents:
            print(f"   üìÑ {doc.id}: {doc.content[:50]}...")
    else:
        print(f"‚ùå Failed to upload documents")
        return
    
    # Step 5: Search Documents
    print_section("Step 5: Searching Documents")
    
    search_queries = [
        "distributed systems",
        "vector databases",
        "fault tolerance",
        "load balancing",
        "consistency models"
    ]
    
    for query in search_queries:
        print(f"\nüîç Searching for: '{query}'")
        results = await storage_manager.search_documents(collection_name, query, limit=3)
        
        if results:
            print(f"   Found {len(results)} results:")
            for i, result in enumerate(results):
                print(f"   {i+1}. Score: {result['score']:.3f} - {result['content'][:60]}...")
        else:
            print("   No results found")
    
    # Step 6: Get Index Statistics
    print_section("Step 6: Index Statistics")
    
    stats = await storage_manager.get_index_stats(collection_name)
    if stats:
        print(f"Collection: {stats['name']}")
        print(f"Vectors: {stats['vectors_count']}")
        print(f"Shards: {stats['shard_count']}")
    else:
        print("‚ùå Failed to get statistics")
    
    # Step 7: Cluster Status
    print_section("Step 7: Cluster Status")
    
    cluster_status = await storage_manager.get_cluster_status()
    if cluster_status:
        print(f"Total nodes: {cluster_status['total_nodes']}")
        print(f"Healthy nodes: {cluster_status['healthy_nodes']}")
        print(f"Total shards: {cluster_status['total_shards']}")
        print(f"Total collections: {cluster_status['total_collections']}")
        print(f"Total vectors: {cluster_status['total_vectors']}")
        print(f"Replication factor: {cluster_status['replication_factor']}")
        print(f"Consistency level: {cluster_status['consistency_level']}")
        
        print("\nNode details:")
        for node in cluster_status.get('nodes', []):
            print(f"   {node['id']}: {node['status']} (load: {node['load']:.2f}, vectors: {node['vector_count']})")
    else:
        print("‚ùå Failed to get cluster status")
    
    # Step 8: Fault Tolerance Demo
    print_section("Step 8: Fault Tolerance Demo")
    
    print("üõ°Ô∏è  Fault Tolerance Features:")
    print("   ‚úÖ Data replication across multiple nodes")
    print("   ‚úÖ Automatic failover when nodes fail")
    print("   ‚úÖ Quorum-based consistency (continues with majority)")
    print("   ‚úÖ Graceful degradation under partial failures")
    
    print("\nüìä In a real scenario:")
    print("   - If node1 fails, data is still available on node2 and node3")
    print("   - Search operations continue with remaining nodes")
    print("   - System automatically recovers when failed node comes back")
    print("   - Load is redistributed to healthy nodes")
    
    # Step 9: Scalability Demo
    print_section("Step 9: Scalability Demo")
    
    print("üìà Scalability Features:")
    print("   ‚úÖ Horizontal scaling - add more nodes")
    print("   ‚úÖ Automatic shard redistribution")
    print("   ‚úÖ Load balancing across nodes")
    print("   ‚úÖ Elastic capacity based on demand")
    
    print("\nüîß To add a new node:")
    print("   curl -X POST 'http://localhost:8000/cluster/nodes' \\")
    print("     -H 'Content-Type: application/json' \\")
    print("     -d '{\"node_id\": \"node4\", \"host\": \"localhost\", \"port\": 8004}'")
    
    # Step 10: Cleanup
    print_section("Step 10: Cleanup")
    
    success = await storage_manager.delete_index(collection_name)
    if success:
        print(f"‚úÖ Deleted collection: {collection_name}")
    else:
        print(f"‚ùå Failed to delete collection: {collection_name}")
    
    # Final Summary
    print_header("Demo Complete!")
    
    print("üéâ Distributed System Features Demonstrated:")
    print("   ‚úÖ Multiple storage nodes with health monitoring")
    print("   ‚úÖ Fault tolerance through data replication")
    print("   ‚úÖ Load balancing and automatic failover")
    print("   ‚úÖ Configurable consistency levels")
    print("   ‚úÖ Horizontal scalability")
    print("   ‚úÖ Real-time cluster monitoring")
    print("   ‚úÖ Academic-grade distributed systems concepts")
    
    print("\nüìö This demonstrates key distributed systems concepts:")
    print("   - Consistent hashing for shard distribution")
    print("   - Quorum-based consensus for consistency")
    print("   - Fault tolerance through replication")
    print("   - Load balancing and auto-scaling")
    print("   - Health monitoring and recovery")
    
    print("\nüöÄ Next Steps:")
    print("   - Test fault tolerance by stopping a node")
    print("   - Add more nodes to see horizontal scaling")
    print("   - Monitor cluster health during operations")
    print("   - Explore the API endpoints for cluster management")

async def main():
    """Main function."""
    print("üéØ Distributed Vector Storage System Demo")
    print("Make sure the vector nodes are running:")
    print("  python start_vector_nodes.py")
    print()
    
    # Wait a bit for nodes to be ready
    print("‚è≥ Waiting for nodes to be ready...")
    await asyncio.sleep(3)
    
    await demo_distributed_system()

if __name__ == "__main__":
    asyncio.run(main()) 